{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load libraries and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/attpit01/SNregression_yeo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/attpit01/SNregression_yeo/scripts/HCP_helper/HCP_helpers.py:81: UserWarning: \n",
      "\n",
      " | Using Nistats with Nilearn versions >= 0.7.0 is redundant and potentially conflicting.\n",
      " | Nilearn versions 0.7.0 and up offer all the functionality of Nistats as well the latest features and fixes.\n",
      " | We strongly recommend uninstalling Nistats and using Nilearn's stats & reporting modules.\n",
      "\n",
      "  import nistats\n"
     ]
    }
   ],
   "source": [
    "from HCP_helpers import *\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path as op\n",
    "scrPath = Path(os.getcwd())\n",
    "rootPath = scrPath.parent.parent\n",
    "print(rootPath)\n",
    "dfPath = op.join(rootPath, 'unrestricted_11_4_2020_2_19_35.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subjects selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 140 subjects for release ['Q1 & Q2']\n",
      "Selected 138 subjects with complete neuropsych data\n",
      "Kept 138 subjects after removing missing values\n",
      "Kept 128 subjects with complete rfMRI datasets\n",
      "Kept 119 subjects with motion <0.15mm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(dfPath)\n",
    "df\n",
    "# keep variables of interest\n",
    "df = df[['Subject','Release','Gender','Age','fMRI_3T_ReconVrs',\n",
    "        'FS_BrainSeg_Vol','MMSE_Score','3T_RS-fMRI_PctCompl',\n",
    "        'PMAT_Compl','NEO-FFI_Compl','MMSE_Compl',\n",
    "        'Non-TB_Compl','VisProc_Compl','DelDisc_Compl',\n",
    "        'SCPT_Compl','IWRD_Compl','VSPLOT_Compl',\n",
    "        'CardSort_Unadj','Flanker_Unadj','ListSort_Unadj',\n",
    "        'PicSeq_Unadj','PicVocab_Unadj','ProcSpeed_Unadj',\n",
    "        'ReadEng_Unadj','IWRD_TOT','PMAT24_A_CR','VSPLOT_TC']]\n",
    "\n",
    "df['Gender'].replace(['F', 'M'],[1, 2],inplace=True)\n",
    "df['fMRI_3T_ReconVrs'].replace(['r177','r177 r227','r227'],[1,2,3],inplace=True)\n",
    "\n",
    "keepSub = (df['Release'] == 'Q2') | (df['Release'] == 'Q1')\n",
    "\n",
    "# keepSub = ((df['Release'] == 'Q1') | (df['Release'] == 'Q2') | (df['Release'] == 'Q3') \n",
    "#            | (df['Release'] == 'S500') | (df['Release'] == 'S900') | (df['Release'] == 'S1200') \n",
    "#            | (df['Release'] == 'MEG2'))\n",
    "\n",
    "print('Selected {} subjects for release {}'.format(np.sum(keepSub),['Q1 & Q2']))\n",
    "\n",
    "# select subjects that have completed all neuropsych\n",
    "keepSub = keepSub & (\n",
    "    (df['PMAT_Compl']==True) &\n",
    "    (df['NEO-FFI_Compl']==True) &\n",
    "    (df['MMSE_Compl']==True) &\n",
    "    (df['Non-TB_Compl']==True) &\n",
    "    (df['VisProc_Compl']==True) &\n",
    "    (df['SCPT_Compl']==True) &\n",
    "    (df['IWRD_Compl']==True) &\n",
    "    (df['VSPLOT_Compl']==True)\n",
    "    )\n",
    "print('Selected {} subjects with complete neuropsych data'.format(np.sum(keepSub)))\n",
    "\n",
    "# FURTHER EXCLUSIONARY CRITERIA: MISSING VALUES\n",
    "keepSub    = np.logical_and(keepSub,np.logical_not(np.isnan(df['CardSort_Unadj'])))\n",
    "keepSub    = np.logical_and(keepSub,np.logical_not(np.isnan(df['VSPLOT_TC'])))\n",
    "keepSub    = np.logical_and(keepSub,np.logical_not(np.isnan(df['PicSeq_Unadj'])))\n",
    "print('Kept {} subjects after removing missing values'.format(np.sum(keepSub)))\n",
    "\n",
    "# COGNITIVE COMPROMISE --> MMSE <26 excluded\n",
    "keepSub    = np.logical_and(keepSub,df['MMSE_Score']>=26)\n",
    "\n",
    "# FURTHER PRUNE SUBJECTS FOR MRI ANALYSIS\n",
    "# Exclusion of subjects who did not complete all RS-fMRI\n",
    "keepSub = np.logical_and(keepSub,df['3T_RS-fMRI_PctCompl']==100)\n",
    "print('Kept {} subjects with complete rfMRI datasets'.format(np.sum(keepSub)))\n",
    "\n",
    "# Exclusion of high-motion subjects\n",
    "# exclude subjects with >0.14 frame-to-frame head motion estimate averged across both rest runs (arbitrary threshold as in Finn et al 2015)\n",
    "fmriRuns = ['rfMRI_REST1_LR', 'rfMRI_REST1_RL']\n",
    "RelRMSMean = np.zeros([len(df['Subject']), len(fmriRuns)],dtype=np.float32)\n",
    "FDsum      = np.zeros([len(df['Subject']), len(fmriRuns)],dtype=np.float32)\n",
    "iSub=0\n",
    "excluded = list()\n",
    "RMSPath = op.join(rootPath,'RMS')\n",
    "for subject in df['Subject']:\n",
    "    if not keepSub[iSub]:\n",
    "        iSub=iSub+1\n",
    "        continue\n",
    "    config.subject=str(subject)\n",
    "    # RelRMSMean\n",
    "    i=0\n",
    "    for config.fmriRun in fmriRuns:\n",
    "\n",
    "        RelRMSMeanFile = op.join(RMSPath,config.subject,config.fmriRun,'Movement_RelativeRMS_mean.txt')\n",
    "        if op.isfile(RelRMSMeanFile):\n",
    "            with open(RelRMSMeanFile,'r') as tmp:\n",
    "                RelRMSMean[iSub,i] = float(tmp.read())\n",
    "        else:\n",
    "            keepSub[iSub]=False\n",
    "            excluded.append(config.subject)\n",
    "            break\n",
    "        i=i+1\n",
    "    if i==len(fmriRuns): # all RelRMSMeanFile exist\n",
    "        if np.any(RelRMSMean[iSub,:] > 0.15):\n",
    "            keepSub[iSub]=False\n",
    "            excluded.append(config.subject)\n",
    "        else:\n",
    "            keepSub[iSub]=True\n",
    "    # total framewise displacement\n",
    "    i=0\n",
    "    for config.fmriRun in fmriRuns:\n",
    "        FDsumFile = op.join(RMSPath,config.subject,config.fmriRun, 'FD_sum.txt')\n",
    "        if not op.isfile(FDsumFile):\n",
    "            motionFile = op.join(RMSPath,config.subject,config.fmriRun,'Movement_Regressors_dt.txt')\n",
    "            if op.isfile(motionFile):\n",
    "                dmotpars = np.abs(np.genfromtxt(motionFile)[:,6:]) #derivatives\n",
    "                headradius=50 #50mm as in Powers et al. 2012\n",
    "                disp=dmotpars.copy()\n",
    "                disp[:,3:]=np.pi*headradius*2*(disp[:,3:]/360)\n",
    "                thisFDsum=np.sum(np.sum(disp,1),0)\n",
    "                with open(FDsumFile,'w') as tmp:\n",
    "                    tmp.write(str(thisFDsum))\n",
    "            else:\n",
    "                break\n",
    "        with open(FDsumFile,'r') as tmp:\n",
    "            FDsum[iSub,i] = float(tmp.read())\n",
    "        i=i+1\n",
    "    iSub=iSub+1\n",
    "\n",
    "# add RelRMSMean and FDsum to the dataframe\n",
    "df['RelRMSMean_REST1'] = np.mean(RelRMSMean[:,0:2],axis=1)\n",
    "df['FDsum_REST1']      = np.mean(FDsum[:,0:2],axis=1)\n",
    "\n",
    "print('Kept {} subjects with motion <0.15mm'.format(np.sum(keepSub)))\n",
    "\n",
    "\n",
    "# PRUNE df \n",
    "df        = df[keepSub]\n",
    "# reindex\n",
    "df.index  = range(df.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory factor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PicVocab_Unadj normality test: p = 0.532616\n",
      "ReadEng_Unadj normality test: p = 0.215002\n",
      "PicSeq_Unadj normality test: p = 0.330511\n",
      "Flanker_Unadj normality test: p = 0.0481468\n",
      "CardSort_Unadj normality test: p = 0.0168717\n",
      "ProcSpeed_Unadj normality test: p = 4.40422e-06\n",
      "PMAT24_A_CR normality test: p = 0.00347337\n",
      "VSPLOT_TC normality test: p = 0.641865\n",
      "IWRD_TOT normality test: p = 4.32077e-06\n",
      "ListSort_Unadj normality test: p = 0.105113\n"
     ]
    }
   ],
   "source": [
    "cogScores = ['PicVocab_Unadj',              # Vocabulary, Language, Crystallized, Global\n",
    "             'ReadEng_Unadj',               # Reading, Language, Crystallized, Global\n",
    "             'PicSeq_Unadj',                # Episodic memory, Fluid, Global\n",
    "             'Flanker_Unadj',               # Executive, Fluid, Global\n",
    "             'CardSort_Unadj',              # Executive, Fluid, Global\n",
    "             'ProcSpeed_Unadj',             # Speed, Executive, Fluid, Global\n",
    "             'PMAT24_A_CR',                 # non-verbal reasoning: Number of Correct Responses, Median Reaction Time for Correct Responses \n",
    "             'VSPLOT_TC',                   # Spatial ability: Total Number Correct, Median Reaction Time Divided by Expected Number of Clicks for Correct \n",
    "             'IWRD_TOT',                    # Verbal memory\n",
    "             'ListSort_Unadj',              # Working memory, Executive, Fluid, Global\n",
    "        ]\n",
    "alpha = 1e-3\n",
    "for score in cogScores:\n",
    "    k2, p = stats.normaltest(df[score])\n",
    "    print(\"{} normality test: p = {:g}\".format(score,p))\n",
    "cogdf      = df[cogScores].copy()\n",
    "\n",
    "# standardize scores\n",
    "standardize = lambda x: (x-x.mean()) / x.std() #* 15. + 100.\n",
    "cogdf = cogdf.pipe(standardize)\n",
    "cogdf.to_csv(op.join(rootPath, 'cogdf.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below should be run in the case of 'computeG' rscript has been performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    G     g_efa     g_cfa  PMAT24_A_CR\n",
      "G            1.000000  0.911461  0.911439     0.638255\n",
      "g_efa        0.911461  1.000000  0.977574     0.740371\n",
      "g_cfa        0.911439  0.977574  1.000000     0.708680\n",
      "PMAT24_A_CR  0.638255  0.740371  0.708680     1.000000\n"
     ]
    }
   ],
   "source": [
    "b4Scores = pd.read_csv(op.join(rootPath, 'b4Scores_EFA.csv')) # bi-factor score from EFA\n",
    "biScores = pd.read_csv(op.join(rootPath, 'biScores_CFA.csv')) # bi-factor score from CFA\n",
    "df['G']      = cogdf['CardSort_Unadj'] + cogdf['Flanker_Unadj'] + cogdf['ProcSpeed_Unadj'] + cogdf['PicVocab_Unadj'] + (\n",
    "            cogdf['ReadEng_Unadj'] + cogdf['PMAT24_A_CR'] + cogdf['VSPLOT_TC'] + cogdf['IWRD_TOT'] + cogdf['PicSeq_Unadj'] + cogdf['ListSort_Unadj'])\n",
    "df['g_efa']  = b4Scores.iloc[:,0]\n",
    "df['g_cfa']  = biScores.iloc[:,0]\n",
    "print(df[['G','g_efa','g_cfa','PMAT24_A_CR']].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure that the selected subjects all have complete MRI runs and performed cognitive tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_MRI = np.genfromtxt(op.join(rootPath, 'subjectsID_SAVE.txt'), dtype=int)\n",
    "for sub in df['Subject']:\n",
    "    if not sub in subj_MRI:\n",
    "        print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreList  = ['g_efa','PMAT24_A_CR',\n",
    "          'Gender','FS_BrainSeg_Vol',\n",
    "          'FDsum_REST1']\n",
    "thisdf = df[scoreList].copy()\n",
    "corr   = thisdf.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.set(style=\"white\")\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", mask=mask, cmap=cmap, vmax=.8, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.savefig(op.join(rootPath,\"confounds.svg\"), format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confound removal assessment\n",
    "Use multiple regression to remove effects of confounds and assess whether there is any correlation left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'brainsize', 'motion', 'PMAT24_A_CR']\n",
      "0.203744, 0.233584, -0.099561, 0.740371\n",
      "-0.000000, -0.000000, -0.000000, 0.712808\n"
     ]
    }
   ],
   "source": [
    "decon = 'decon'\n",
    "\n",
    "if decon == 'megatrawlDecon':\n",
    "    confounds=['gender','age','age^2','gender*age','gender*age^2','brainsize','motion','recon']\n",
    "elif decon == 'megatrawlDecon+IQ':\n",
    "    confounds=['gender','age','age^2','gender*age','gender*age^2','brainsize','motion','recon','PMAT24_A_CR']\n",
    "elif decon == 'decon':\n",
    "    # confounds=['gender','age','brainsize','motion','recon']\n",
    "    confounds=['gender','brainsize','motion']\n",
    "elif decon == 'decon+IQ':\n",
    "    confounds=['gender','age','brainsize','motion','recon','PMAT24_A_CR']\n",
    "elif decon == 'noDecon':\n",
    "    confounds=[]\n",
    "\n",
    "# allConfounds=['gender','age','age^2','gender*age','gender*age^2','brainsize','motion','recon','PMAT24_A_CR']\n",
    "allConfounds=['gender','brainsize','motion','PMAT24_A_CR']\n",
    "# make a matrix with all confounds\n",
    "conMatAll = None\n",
    "for confound in allConfounds:\n",
    "    if confound == 'gender':\n",
    "        conVec = df['Gender']\n",
    "    elif confound == 'age':\n",
    "        conVec = df['Age_in_Yrs']\n",
    "    elif confound == 'age^2':\n",
    "        conVec = np.square(df['Age_in_Yrs'])\n",
    "    elif confound == 'gender*age':\n",
    "        conVec = np.multiply(df['Gender'],df['Age_in_Yrs'])\n",
    "    elif confound == 'gender*age^2':\n",
    "        conVec = np.multiply(df['Gender'],np.square(df['Age_in_Yrs']))\n",
    "    elif confound == 'brainsize':\n",
    "        conVec = df['FS_BrainSeg_Vol']\n",
    "    elif confound == 'motion':\n",
    "        conVec = df['FDsum_REST1']\n",
    "    elif confound == 'recon':\n",
    "        conVec = df['fMRI_3T_ReconVrs']\n",
    "    elif confound == 'PMAT24_A_CR':\n",
    "        conVec = df['PMAT24_A_CR']\n",
    "    # add to conMat\n",
    "    if conMatAll is None:\n",
    "        conMatAll = np.array(np.ravel(conVec))\n",
    "    else:\n",
    "        conMatAll = np.vstack((conMatAll,conVec))\n",
    "conMatAll = conMatAll.T\n",
    "\n",
    "# make a matrix with just the confounds used\n",
    "conMat = None\n",
    "for confound in confounds:\n",
    "    if confound == 'gender':\n",
    "        conVec = df['Gender']\n",
    "    elif confound == 'age':\n",
    "        conVec = df['Age_in_Yrs']\n",
    "    elif confound == 'age^2':\n",
    "        conVec = np.square(df['Age_in_Yrs'])\n",
    "    elif confound == 'gender*age':\n",
    "        conVec = np.multiply(df['Gender'],df['Age_in_Yrs'])\n",
    "    elif confound == 'gender*age^2':\n",
    "        conVec = np.multiply(df['Gender'],np.square(df['Age_in_Yrs']))\n",
    "    elif confound == 'brainsize':\n",
    "        conVec = df['FS_BrainSeg_Vol']\n",
    "    elif confound == 'motion':\n",
    "        conVec = df['FDsum_REST1']\n",
    "    elif confound == 'recon':\n",
    "        conVec = df['fMRI_3T_ReconVrs']\n",
    "    elif confound == 'PMAT24_A_CR':\n",
    "        conVec = df['PMAT24_A_CR']\n",
    "    # add to conMat\n",
    "    if conMat is None:\n",
    "        conMat = np.array(np.ravel(conVec))\n",
    "    else:\n",
    "        conMat = np.vstack((conMat,conVec))\n",
    "conMat = conMat.T\n",
    "\n",
    "# check correlations with all confounds\n",
    "print(allConfounds)\n",
    "score = 'g_efa'\n",
    "# correlations before\n",
    "corrBef = []\n",
    "for i in range(len(allConfounds)):\n",
    "    corrBef.append(stats.pearsonr(conMatAll[:,i].T,np.ravel(df[score]))[0])\n",
    "print(', '.join('{:03f}'.format(k) for k in corrBef))\n",
    "# regress out confounds\n",
    "regr        = linear_model.LinearRegression()\n",
    "regr.fit(conMat, np.ravel(df[score]))\n",
    "fittedvalues = regr.predict(conMat)\n",
    "deconScore   = np.ravel(df[score]) - np.ravel(fittedvalues)\n",
    "# correlations after\n",
    "corrAft = []\n",
    "for i in range(len(allConfounds)):\n",
    "    corrAft.append(stats.pearsonr(conMatAll[:,i].T,deconScore)[0])\n",
    "print(', '.join('{:03f}'.format(k) for k in corrAft))\n",
    "df['g_efa_decon'] = deconScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114924\n",
      "119833\n",
      "123117\n",
      "140420\n",
      "150423\n",
      "151223\n",
      "156637\n",
      "191437\n",
      "250427\n",
      "677968\n",
      "788876\n",
      "992774\n"
     ]
    }
   ],
   "source": [
    "subj_MRI = np.genfromtxt(op.join(rootPath, 'subjectsID_SAVE.txt'), dtype=int)\n",
    "fc_keep = []\n",
    "for sub in subj_MRI:\n",
    "    if not sub in np.array(df['Subject']):\n",
    "        print(sub)\n",
    "    fc_keep.append(sub in np.array(df['Subject']))\n",
    "df_fc = pd.read_csv(op.join(rootPath, 'fc.csv'),header=None)\n",
    "df_fc = df_fc.iloc[fc_keep,:]\n",
    "df_fc.to_csv(op.join(rootPath, 'fc_z_sel.csv'), index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb6f993b93b39a0777d48adbfd9083e4cf81b6153d26a9ac25f4c1ba823c2d58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
